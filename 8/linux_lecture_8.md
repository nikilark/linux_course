# Розділ 8: Диски та файлові системи

Розділи — це логічні частини всього диска, в Linux вони позначаються числом після цілого блочного пристрою.

Ядро представляє кожен розділ як блоковий пристрій, як і весь диск. Розділи записуються на невеликій ділянці диска, яка називається таблицею розділів.

![Типова схема диску Linux](images/Figure4-1.png)

Наступним рівнем після розділу є файлова система, база даних файлів і каталогів, до яких ви звикли для взаємодії в просторі користувача.

![Доступ до диску](images/Figure4-2.png)

## Розбиття дискових пристроїв

Існує багато видів таблиць розділів. Традиційна таблиця – це та, що міститься в головному завантажувальному записі (Master Boot Record — MBR).

Новішим стандартом є таблиця розділення глобальних унікальних ідентифікаторів (Globally Unique Identifier Partition Table — GPT). Ось деякі інструменти для роботи з розділами Linux:

     * parted: текстовий інструмент, який підтримує як MBR, так і GPT
     * gparted: графічна версія parted
     * fdisk: традиційний текстовий інструмент розбиття диска Linux. fdisk не підтримує GPT
     * gdisk: версія fdisk, яка підтримує GPT, але не підтримує MBR

Короткий огляд роботи з  parted:

1. Виведення таблиці розділів

     ```bash
     sudo parted /dev/sda print
     ```

2. Створення новогу розділу

     ```bash
     sudo parted /dev/sda mkpart primary ext4 1MiB 500MiB
     ```

3. Видалення розділу

     ```bash
     sudo parted /dev/sda rm 1
     ```

4. Зміна розміру розділу

     ```bash
     sudo parted /dev/sda resize 1 1GiB
     ```

![Робота з parted](images/parted.png)

### Перегляд таблиці розділів

Ви можете переглянути таблицю розділів вашої системи за допомогою parted -l. Розділ MBR може бути основного, розширеного та логічного типу (primary, extended, logical). Основний розділ — це звичайний підрозділ диска.

Базова таблиця MBR обмежена чотирма основними розділами, тому, якщо вам потрібно більше чотирьох, ви призначаєте один розділ як розширений.

### Зміна таблиць розділів

Зміна таблиці розділів ускладнює відновлення будь-яких даних на розділах, які ви видаляєте, оскільки це змінює початкову точку відліку для файлової системи, вам потрібно переконатися, що жоден розділ на вашому цільовому диску не  використовується.

Для створення розділів можна використовувати різні інструменти, наприклад _parted_, _gparted_, _gdisk_ або _fdisk_. _fdisk_ і _parted_ змінюють розділи повністю в просторі користувача.

### Геометрія диска та розділу

Диск складається з пластини, що обертається на шпинделі, з головкою, прикріпленою до рухомої руки, яка може обертатися по радіусу диска.

![Жорсткий диск](images/Figure4-3.png)

Навіть якщо ви можете уявити собі жорсткий диск як блоковий пристрій із довільним доступом до будь-якого блоку, потенційно можливі серйозні наслідки для продуктивності, якщо ви не будете уважні до того, як ви розміщуєте дані на диску.

### Твердотільні диски (SSD)

У твердотільні дисках (SSD) довільний доступ не є проблемою, оскільки немає головки, щоб пронести по диску, але деякі міркування все ще релевантні.

Наприклад, _вирівнювання розділів_ (дані зчитуються блоками фіксованого розміру, якщо дані розміщені у двох блоках, вам потрібно виконати два читання, навіть якщо обсяг даних для читання менший за розмір блоку).

## Файлові системи

Файлова система є формою бази даних; вона забезпечує структуру для перетворення простого блокового пристрою в складну ієрархію файлів і підкаталогів, зрозумілу користувачам.

Файлові системи також традиційно реалізуються в ядрі, але існують також файлові системи в просторі користувача (FUSE) і віртуальні файлові системи (VFS).

### Типи файлової системи

Це найпоширеніші типи файлових систем для зберігання даних. Назви типів, які розпізнає Linux, у круглих дужках поруч із назвами файлових систем:

     * Четверта розширена файлова система (ext4): поточна ітерація лінії файлових систем, рідних для Linux
     * ISO 9660 (iso9660): це стандарт CD-ROM (більшість CD-ROM використовують деякі варіанти стандарту ISO 9660)
     * Файлові системи FAT (msdos, vfat, umsdos): відносяться до систем Microsoft. Більшість сучасних файлових систем Windows використовують файлову систему vfat для отримання повного доступу з Linux
     * HFS+ (hfsplus): стандарт Apple, який використовується в більшості систем Macintosh

### Створення файлової системи

Щоб створити файлову систему, як і у випадку з розділенням, ви зробите це в просторі користувача, оскільки процес простору користувача може безпосередньо отримувати доступ до блокового пристрою та керувати ним.

Утиліта _mkfs_ може створювати багато видів файлових систем:

```bash
# creates an ext4 filesystem
mkfs -t ext4 /dev/sdf2 
```

_mkfs_ — це лише інтерфейс для серії програм створення файлової системи, mkfs.fs, де fs — тип файлової системи.

Отже, коли ви запускаєте mkfs -t ext4, mkfs, у свою чергу, запускає mkfs.ext4, розташований у _/sbin/mkfs.\*_

### Монтування файлової системи

Процес підключення файлової системи називається монтуванням. Коли система завантажується, ядро зчитує деякі конфігураційні дані та монтує кореневий каталог (/) на основі конфігураційних даних. Щоб підключити файлову систему, ви повинні знати наступне:

     * Пристрій файлової системи (де зберігаються фактичні дані файлової системи)
     * Тип файлової системи
     * Точка монтування — це: місце в ієрархії каталогів поточної системи, куди буде приєднано файлову систему

```bash
# The format of the command is: mount -t type device mountpoint
mount -t ext4 /dev/sdf2 /home/extra
```

### UUID файлової системи

Імена пристроїв можуть змінюватися, оскільки вони залежать від порядку, у якому ядро знаходить пристрої. Щоб вирішити цю проблему, ви можете визначити та змонтувати файлові системи за їхнім універсальним унікальним ідентифікатором (UUID), програмним стандартом.

Щоб переглянути список пристроїв і відповідні файлові системи та UUID у вашій системі, скористайтеся програмою _blkid_.

Щоб змонтувати файлову систему за її UUID, використовуйте `mount UUID=<uuid> <Mount point>`

### Буферизація диска, кешування та файлові системи

Буфери Unix записують на диск, коли ви демонтуєте файлову систему за допомогою umount, ядро автоматично синхронізується з диском.

Ви можете змусити ядро записати зміни у своєму буфері на диск, виконавши команду _sync_.

### Параметри монтування файлової системи

Деякі важливі параметри команди монтування:

     * -t: вказати тип файлової системи
     * -r: монтувати файлову систему в режимі лише для читання
     * -n: щоб переконатися, що монтування не намагається оновити базу даних монтування системи (/etc/mtab)
     * -o: активувати опцію файлової системи (-o <параметр>). Деякі з цих варіантів:
         * exec, noexec: вмикає або вимикає виконання програм у файловій системі
         * suid, nosuid: вмикає або вимикає програми setuid
         * ro Монтує файлову систему в режимі лише для читання (як і короткий параметр -r)
         * rw Монтує файлову систему в режимі читання-запису
         * conv=rule (файлові системи на основі FAT) Перетворює символи нового рядка у файлах на основі певних правил.

### Перемонтування файлової системи

Щоб повторно підключити поточну змонтовану файлову систему до тієї самої точки монтування з іншими параметрами монтування, виконайте такі дії

`mount <options> -o remount <mounting point>`

### Таблиця файлової системи /etc/fstab

Системи Linux зберігають постійний список файлових систем і параметрів у _/etc/fstab_. Кожен рядок описує файлову систему з такими полями:

     * Пристрій або UUID
     * Точка монтування — вказує, куди підключили файлову систему
     * Тип файлової системи
     * Параметри, розділені комами
     * Інформація про резервне копіювання для використання командою dump
     * Порядок перевірки цілісності файлової системи

### Альтернативи /etc/fstab

Альтернативою файлу _/etc/fstab_ є каталог _/etc/fstab.d_, який містить окремі файли конфігурації файлової системи та для налаштування одиниць _systemd_ для файлових систем.

### Ємність файлової системи

Щоб переглянути розмір і використання поточних змонтованих файлових систем, скористайтеся командою _df_. Вихід містить:

     * Filesystem: пристрій файлової системи
     * 1024-blocks: загальна ємність файлової системи в блоках по 1024 байта
     * Used: кількість зайнятих блоків
     * Available: кількість безкоштовних блоків
     * Capacity: відсоток використовуваних блоків
     * Mounted on: точці монтування

Якщо ваш диск заповнений і вам потрібно знати, де виділено місце, скористайтеся командою _du_.

### Перевірка та відновлення файлових систем

Якщо у змонтованій файловій системі є помилки, це може призвести до втрати даних і збою системи. Інструментом для перевірки файлової системи є _fsck_

Існують різні версії `fsck` для кожного типу файлової системи, яку підтримує Linux.

Щоб запустити `fsck` в інтерактивному ручному режимі (-n для автоматичного режиму), укажіть пристрій або точку монтування (як зазначено в /etc/fstab) як аргумент:

```bash
fsck /dev/sdb1
```

- Перевірка файлових систем ext3 і ext4

Ви можете змонтувати несправну файлову систему ext3 або ext4 у режимі ext2, оскільки ядро не монтуватиме файлову систему ext3 або ext4 із непорожнім журналом.

Щоб скинути журнал із файлової системи ext3 або ext4 до звичайної бази даних файлової системи, запустіть e2fsck так: `e2fsck –fy /dev/disk_device`

- Найгірший випадок

Інструмент `debugfs` дозволяє вам переглядати файли у файловій системі та копіювати їх в інше місце.

### Файлові системи спеціального призначення

Більшість версій Unix мають файлові системи, які служать системними інтерфейсами. Тобто замість того, щоб служити лише засобом для зберігання даних на пристрої, файлова система може представляти системну інформацію, таку як ідентифікатори процесу та діагностику ядра.

Спеціальні типи файлових систем, які зазвичай використовуються в Linux, включають наступне:

     * proc: змонтовано до /proc. Кожен пронумерований каталог у /proc є ідентифікатором поточного процесу в системі.
     Файл /proc/self представляє поточний процес
     * sysfs: змонтовано до /sys
     * tmpfs монтується в /run та в інших місцях. tmpfs дозволяє використовувати фізичну пам'ять і простір підкачки як тимчасове сховище

## Swap

Якщо у вас вичерпано реальну пам’ять, система віртуальної пам’яті Linux може автоматично переміщувати частини пам’яті на дискове сховище та з нього (свопінг).

Область диска, яка використовується для зберігання сторінок пам’яті, називається простором підкачки (для перегляду поточної статистики пам'ятті використовуйте команду _free_).

### Використання розділу диска як місця підкачки

Щоб використовувати весь розділ диска як своп, переконайтеся, що розділ порожній, і запустіть `mkswap dev`, де `dev` — це пристрій розділу. Потім виконайте `swapon dev`, щоб зареєструвати простір у ядрі.

### Використання файлу як місця підкачки

Використовуйте ці команди, щоб створити порожній файл, ініціалізувати його як простір свопу та додати до пулу підкачки:

```bash
dd if=/dev/zero of=<the swap file> bs=1024k count=<desired size in mb> 
mkswap <the swap file>
swapon <the swap file>
```

### Скільки свопу вам потрібно?

Загальноприйнята думка Unix говорить, що ви завжди повинні резервувати принаймні вдвічі більше, ніж у вас є реальна пам’ять.

### Всередині традиційної файлової системи

Традиційна файлова система Unix має два основні компоненти: пул блоків даних, де ви можете зберігати дані, і систему бази даних, яка керує пулом даних. База даних зосереджена навколо структури даних _inode_.

_inode_ — це набір даних, який описує певний файл, включаючи його тип, дозволи та місце розташування даних файлу в пулі даних. _inode_ ідентифікуються номерами, зазначеними в таблиці _inode_.

![Файлова система на рівні користувача](images/Figure4-4.png)

![Дескриптори файлової системи](images/Figure4-5.png)

### Перегляд деталей Inode

Щоб переглянути номери _inode_ для будь-якого каталогу, скористайтеся командою `ls -i`. Щоб отримати детальнішу інформацію про _inode_, використовуйте команду _stat_.

## Шифрування дисків

Linux використовує Linux Unified Key Setup (LUKS) для шифрування даних на дисках. LUKS — це стандарт шифрування даних, який використовує ключі для шифрування та розшифрування даних.

Повне шифрування диску можливе тільки на етапі встановлення операційної системи. При цьому шифрується всі дані, включно зі swap.

Коли ви доступаєтесь до зашифрованого диску, операційна система вимагає від вас пароль для розшифрування даних. Якщо ви вводите правильний пароль, LUKS розшифровує ключ (_master key_), який використовується для розшифрування даних на диску.

Надалі LUKS буде використовувати цей ключ для розшифрування даних на диску коли вони вам знадобляться. Через це продуктивність системи трохи зменшується, проте завдяки апаратній підтримці шифрування даних це не помітно для звичайного користувача.

## Менеджер логічних томів LVM

Менеджер логічних томів (LVM) — це шар абстракції, який дозволяє вам створювати віртуальні томи, які можуть бути більшими, ніж фізичні пристрої, і змінювати розмір віртуальних томів без перезавантаження системи.

Ви створюєте набір фізичних томів (Physical Volumes — PV), які ви об'єднуєте в групу фізичних томів (Volume Group — VG), а потім ви вибираєте частину цього об'єднання для створення логічних томів (Logical Volumes — LV).

![Менеджер логічних томів](images/lvm.png)

Логічні тома — це просто блочні пристрої, які мають власні файлові системи, які ви можете монтувати та використовувати як будь-який інший блоковий пристрій. Це схоже на розділення диска, але з додатковими можливостями.

LVM дозволяє виконувати наступні задачі:

     * Додавати більше фізичних томів до групи, щоб збільшити її обсяг
     * Видаляти фізичні томи з групи, якщо група має достатньо місця для розміщення даних
     * Змінювати розмір логічних томів без перезавантаження системи

Менеджер LVM часто використовується в хмарних середовищах, де він дає необхідну гнучкість для розміщення віртуальних машин.

### Робота з менеджером LVM

Більшість інструментів lvm побудовані на загальній команді _lvm_, яка викликає інтерактивний оболонковий інтерфейс. Ви можете використовувати команди _pv*, vg*, lv*_ для роботи з фізичними томами, групами фізичних томів та логічними томами відповідно. Наприклад, команда _vgs_ має той самий ефект, що й введення _vgs_ в інтерактивному режимі _lvm_.

### Групи томів та їх перелік

Група томів — це набір фізичних томів, які об'єднуються разом, щоб створити великий пул даних.

Щоб переглянути список груп томів, скористайтеся командою _vgs_.

![Групи томів](images/vgs.png)

Вивід команди має наступні поля:

     * VG: ім'я групи томів
     * #PV: кількість фізичних томів у групі
     * #LV: кількість логічних томів у групі
     * #SN: кількість фізичних томів, які можуть бути додані до групи
     * Attr: атрибути групи томів
     * VSize: загальний розмір групи томів
     * VFree: кількість вільного місця в групі томів

Для більш детальної інформації про групу томів використовуйте команду _vgdisplay_.

### Перелік логічних томів

Щоб переглянути список логічних томів, скористайтеся командою _lvs_ (або _lvdisplay_ для більш детальної інформації).

![Логічні томи](images/lvs.png)

Головними в виводі є наступні стовпці:

     * LV: ім'я логічного тому
     * VG: ім'я групи томів, до якої він належить
     * Attr: атрибути логічного тому
     * LSize: розмір логічного тому

### Пристрої логічних томів

Пристрої з блоками даних логічних томів зазвичай знаходяться за адресами _/dev/dm-*_, де _*_ — це номер логічного тому. Через випадковий порядок надання пристроїв, ви не можете визначити, який пристрій відповідає якому логічному тому, тому LVM створює символьні посилання на ці пристрої у каталозі _/dev/vg_name/lv_name_.

Також в дистрибутивах часто є додаткове місце для символічних посилань на пристрої логічних томів у каталозі _/dev/mapper_. Формат іменування тут — _/dev/mapper/vg_name-lv_name_.

Саме посилання в _/dev/mapper_ варто використовувати для монтування логічних томів.

### Перелік фізичних томів

Щоб переглянути список фізичних томів, скористайтеся командою _pvs_ (або _pvdisplay_ для більш детальної інформації).

![Фізичні томи](images/pvs.png)

Головними в виводі є наступні стовпці:

     * PV: ім'я фізичного тому
     * VG: ім'я групи томів, до якої він належить
     * Fmt: формат фізичного тому
     * Attr: атрибути фізичного тому
     * PSize: розмір фізичного тому
     * PFree: кількість вільного місця в фізичному томі

За допомогою фізичних томів створюються групи томів, які використовуються для створення логічних томів. Кожен фізичний том, крім імені блочного пристрою, має ще метадані (_physical volume metadata_), які вказують, чи він використовується в групі томів, та інші атрибути.

## Побудова системи логічних томів

### Створення групи томів

Щоб створити групу томів, використовуйте команду _vgcreate_, вказавши ім'я групи томів та принаймні один фізичний том.

```bash
vgcreate vg_name /dev/sdb1
```

![Створення групи томів](images/vgcreate.png)

Ви також можете створити фізичний том самостійно, використовуючи команду _pvcreate_. Однак це необхідно лише в тому випадку, якщо ви хочете використовувати фізичний том, який вже містить дані.

В іншому випадку, якщо ви хочете використовувати весь пристрій, ви можете вказати його ім'я у команді _vgcreate_, і LVM автоматично створить фізичний том.

Після створення групи томів ви можете переглянути її за допомогою команди _vgs_. Якщо група не відображається, можете використати команду _pvscan_ для оновлення списку груп томів.

Після цього можна додати до групи томів новий фізичний том, використовуючи команду _vgextend_.

![Розширення групи томів](images/vgextend.png)

### Створення логічних томів

Щоб створити логічний том, використовуйте команду _lvcreate_, вказавши ім'я групи томів, розмір логічного тому та ім'я логічного тому.

![Створення логічного тому](images/lvcreate.png)

Для вказання розміру в байтах треба використовувати ключ _--size_, а для вказання розміру в фізичних екстентах — ключ _--extents_. Фізичний екстент — це найменша одиниця розміру, яку можна використовувати для створення логічних томів, рівна 4 МБ за замовчуванням.

_--type linear_ є найпростішим типом логічного тому, який використовує простий лінійний метод розміщення даних на фізичних томах. Він використовується за замовчуванням, тому його можна опускати.

### Створення розділів файлової системи на логічних томах

Після створення логічного тому ви можете створити на ньому файлову систему, використовуючи команду _mkfs_, як і для звичайного розділу.

![Створення файлової системи](images/lvm_mkfs.png)

### Видалення логічних томів

Якщо ви з'ясували, що один з фізичних томів виявився непотрібним, ви можете видалити логічний том, використовуючи команду _lvremove_.

![Видалення логічного тому](images/lvremove.png)

Якщо не вказати слеш, то команда _lvremove_ спробує видалити всі тома в групі томів.

### Зміна розміру логічних томів

Ви можете змінити розмір логічного тому, використовуючи команду _lvresize_ навіть коли він використовується. Це дозволяє вам збільшити розмір логічного тому, якщо ви виявите, що він занадто малий.

Загалом, ви маєте змінити розмір як логічного тому, так і файлової системи, яка знаходиться на ньому. Однак утиліта _lvresize_ може зробити це за вас, якщо ви вказали ключ _-r_.

```bash
lvresize -r -l +100%FREE myvg/mylv1
```

![Зміна розміру логічного тому](images/lvresize.png)

![Зміна розміру файлової системи](images/fsadm.png)

_fsadm_ — це, грубо кажучи, набір сценаріїв для дій з файловими системами. Наприклад, він може викликати інструмент _resize2fs_ для зміни розміру файлової системи.

Збільшити розмір файлової системи _ext2/3/4_ можна, коли вона змонтована, але зменшити — ні. Щоб зменшити розмір файлової системи, вона повинна бути розмонтована.

## Реалізація LVM

Робота, виконувана LVM (або LVM2 в поточних системах) досить складна, тому ядро не хотіло б тим займатися.

Насправді менеджер LVM — це просто набір утиліт простору користувача, які взаємодіють з ядром через спеціальний інтерфейс, який називається _device-mapper_.

### Пошук фізичних томів

Коли LVM запускається, він шукає фізичні томи, які він може використовувати. Він робить це, переглядаючи всі блочні пристрої в системі, і визначає, чи вони вже використовуються LVM.

На початку кожного фізичного тому є метадані, які вказують, чи він використовується LVM, та інші атрибути. Утиліти LVM, такі як _pvscan_, _lvs_, _vgcreate_ та _lvcreate_, використовують ці метадані для визначення, які фізичні томи вони можуть використовувати.

### Драйвер пристрою device-mapper

Після того, як LVM визначив, які фізичні томи він може використовувати, він викликає драйвер пристрою _device-mapper_ для ініціалізації пристроїв та завантажити їх в таблиці пристроїв.

Щоб простежити за роботою _device-mapper_, ви можете використовувати команду _dmsetup_.

![dmsetup info](images/dmsetup_info.png)

![dmsetup table](images/dmsetup_table.png)

## RAID

RAID (Redundant Array of Independent Disks) - це технологія, яка дозволяє об'єднати кілька фізичних дисків в єдиний логічний пристрій для забезпечення високої надійності даних або високої швидкості передачі даних або обидвох.

Основні рівні RAID включають у себе:

1. **RAID 0**: Не надійний, але швидкий. Дані розподіляються між дисками (стріпінг), що дозволяє збільшити швидкість читання/запису, але втрата хоча б одного диску призводить до втрати всіх даних.

2. **RAID 1**: Дзеркальне відображення. Дані записуються на два (або більше) диски одночасно, що забезпечує дублювання даних і, таким чином, високу надійність. Однак це не дозволяє збільшити швидкість.

3. **RAID 5**: Обертовий паритет. Дані та паритетні блоки записуються на всі диски, що забезпечує як надійність (в разі виходу з ладу одного диска, дані можуть бути відновлені з інших дисків), так і збільшення простору диска і швидкості передачі даних.

4. **RAID 6**: Подвійний обертовий паритет. Аналогічний RAID 5, але з двома паритетними блоками, що дозволяє відновлення даних у випадку виходу з ладу до двох дисків.

5. **RAID 10 (1+0)**: Комбінація RAID 1 і RAID 0. Дані дзеркально відображаються на пару дисків (RAID 1), але ці пари об'єднуються в стріповану конфігурацію (RAID 0), що дозволяє отримати як високу швидкість, так і високу надійність.

### Паритет в RAID

Паритет (парність) в контексті RAID - це додаткові дані, які обчислюються на основі даних, що зберігаються на дисках, і використовуються для відновлення втрачених даних у випадку, якщо один з дисків відмовить. Це дозволяє RAID забезпечувати надійність даних, не збільшуючи обсяг даних, як це відбувається у дзеркальних рівнях RAID.

У рівнях RAID з паритетом, таких як RAID 5 або RAID 6, паритетні дані обчислюються на основі даних, що зберігаються на інших дисках. Наприклад, у RAID 5 кожен блок даних на диску супроводжується блоком паритету, який обчислюється як XOR (логічне "виключне або") всіх бітів відповідних блоків даних на інших дисках. У RAID 6 є два блоки паритету, які дозволяють відновлювати дані навіть при виході з ладу двох дисків.

Коли один диск відмовляє, RAID контролер може використовувати паритетні дані для відновлення втрачених даних, перерахувавши або відновивши відповідні дані на основі інформації про паритет.

### RAID 0

RAID 0 (також відомий як "стріпінг") - це рівень RAID, який розподіляє дані на два або більше дисків без додаткової резервної інформації, такої як паритет або дублювання. У RAID 0 дані розбиваються на блоки фіксованого розміру і записуються на різних дисках, що дозволяє одночасно читати та записувати дані на всі диски, що підвищує швидкість вводу/виводу.

![RAID 0](images/raid0.png)

Основні характеристики RAID 0:

1. **Продуктивність**: RAID 0 підвищує продуктивність за рахунок розподілу даних між дисками. Оскільки читання та запис на диски відбуваються паралельно, загальна швидкість доступу може бути значно вищою, ніж у випадку окремих дисків.

2. **Відсутність зайвих даних**: Однак, RAID 0 не забезпечує ніякої зайвої резервності даних. Якщо один з дисків відмовить, це може призвести до втрати всіх даних на RAID.

3. **Складність відновлення**: Оскільки в RAID 0 відсутня резервна інформація, відновлення даних після відмови диска є дуже складним або неможливим без спеціалізованих програм або сервісів відновлення.

4. **Використання дискового простору**: RAID 0 використовує всі диски для зберігання даних, тому він має ефективність використання дискового простору 100%, що означає, що він не має додаткових втрат простору через резервні копії даних або паритет.

RAID 0 найчастіше використовується в ситуаціях, де важлива висока продуктивність, але не критична надійність даних, наприклад, для тимчасових або кешових даних, які можуть бути легко відновлені з інших джерел.

### RAID 1

RAID 1 (також відомий як "дзеркальне відображення") - це рівень RAID, який забезпечує резервне копіювання даних шляхом дублювання на два або більше диски. У RAID 1 дані записуються на один диск (або групу дисків) і потім копіюються на інший диск (або групу дисків), створюючи точну копію даних. Це забезпечує високий рівень надійності та відновлюваності даних.

![RAID 1](images/raid1.png)

Основні характеристики RAID 1:

1. **Надійність**: Основна перевага RAID 1 - надійність. Якщо один з дисків відмовить, дані залишаються доступними на іншому диску, що дозволяє системі продовжувати працювати без втрати даних.

2. **Продуктивність читання**: Читання даних відбувається з обох дисків, що може підвищити швидкодію читання даних, особливо в ситуаціях з великим обсягом читання.

3. **Низька ефективність дискового простору**: RAID 1 вимагає додаткового дискового простору для створення резервних копій даних. Наприклад, якщо в системі є два диски, реально доступний дисковий простір буде лише половина від загальної кількості дисків.

4. **Потреба в двох або більше дисках**: Для налаштування RAID 1 потрібно щонайменше два фізичних диска.

5. **Висока вартість**: Через потребу у подвійних дисках, RAID 1 може бути вищою вартістью у порівнянні з іншими рівнями RAID.

RAID 1 використовується в ситуаціях, коли надійність та відновлення даних є критичними, але можливість швидкого читання даних не є пріоритетною. Він підходить для використання в серверах файлів, баз даних та інших критичних системах, де важливо уникнути втрати даних у випадку відмови диска.

### RAID 4

RAID 4 - це рівень RAID, який використовує блочне розподілення даних та незалежність парності. У RAID 4 дані розподіляються по всіх дисках, за винятком одного, який використовується для зберігання парності. Це означає, що кожен блок даних пишеться на окремі диски, а блок парності пишеться на один з дисків. Якщо один з дисків відмовить, його вміст може бути відновлено за допомогою парності та даних на інших дисках.

![RAID 4](images/raid4.png)

Основні характеристики RAID 4:

1. **Надійність**: RAID 4 забезпечує захист даних від втрати через відмову одного з дисків. Якщо один диск відмовить, дані можуть бути відновлені за допомогою парності та даних на інших дисках.

2. **Висока продуктивність читання**: Оскільки дані розподіляються по всіх дисках, читання може відбуватися паралельно з кількох дисків, що підвищує продуктивність читання.

3. **Низька продуктивність запису**: Запис даних відбувається на основний диск та диск парності, що може створювати _bottleneck_ (затримку у найбільш вузькому місці) на диску парності у високоінтенсивних системах запису.

4. **Потреба у мінімум трьох дисках**: Для налаштування RAID 4 потрібно щонайменше три фізичних диска: два для даних і один для парності.

5. **Висока вартість**: Через потребу у додаткових дисках для парності RAID 4 може бути вищою вартістю у порівнянні з іншими рівнями RAID.

RAID 4 використовується там, де важлива висока продуктивність читання і низька продуктивність запису, а також де є потреба у захисті даних від втрати. Він може бути використаний для систем з файловими серверами, які мають велику кількість читання та помірну кількість запису, або для використання у критичних системах, де важливо уникнути втрати даних у випадку відмови диска.

### RAID 5

RAID 5 - це рівень RAID, який використовує блочне розподілення даних та розподілену парність. У RAID 5 дані розподіляються по всіх дисках, але, на відміну від RAID 4, парність розподіляється також по всіх дисках. Це означає, що кожен блок даних та парності пишеться на різні диски. Якщо один з дисків відмовить, дані можуть бути відновлені за допомогою парності та даних на інших дисках.

![RAID 5](images/raid5.png)

Основні характеристики RAID 5:

1. **Надійність**: RAID 5 забезпечує захист даних від втрати через відмову одного з дисків. Якщо один диск відмовить, дані можуть бути відновлені за допомогою парності та даних на інших дисках.

2. **Добра продуктивність читання і запису**: Через розподілену парність читання та запис можуть відбуватися паралельно з кількох дисків, що підвищує продуктивність обох операцій.

3. **Ефективність простору**: У RAID 5 диск для парності займається тільки один. Решта простору використовується для зберігання даних.

4. **Потреба у мінімум трьох дисках**: Для налаштування RAID 5 потрібно щонайменше три фізичних диска: два для даних і один для парності.

5. **Висока вартість**: Через потребу у додаткових дисках для парності RAID 5 може бути вищою вартістю у порівнянні з іншими рівнями RAID.

RAID 5 широко використовується у системах, де потрібна добра продуктивність читання та запису, а також надійність даних. Він підходить для використання у файлових серверах, базах даних та інших додатках, де важлива комбінація продуктивності та надійності.

### RAID 6

RAID 6 - це рівень RAID, який подібний до RAID 5, але з додатковим рівнем парності. У RAID 6, подібно до RAID 5, дані розподіляються по всіх дисках, але відмінність полягає у тому, що є два блоки парності, які розподіляються по всіх дисках. Це означає, що RAID 6 може витримати відмову двох дисків без втрати даних.

![RAID 6](images/raid6.png)

Основні характеристики RAID 6:

1. **Дві рівні парності**: RAID 6 має два блоки парності, що дозволяє витримати відмову двох дисків без втрати даних.

2. **Висока надійність**: Благодаря двом рівням парності, RAID 6 забезпечує високий рівень надійності даних.

3. **Добра продуктивність читання і запису**: Через розподілену парність читання та запис можуть відбуватися паралельно з кількох дисків, що підвищує продуктивність обох операцій.

4. **Ефективність простору**: Як і у RAID 5, один диск використовується для зберігання парності, що дозволяє ефективно використовувати простір на дисках.

5. **Потреба у мінімум чотирьох дисках**: Для створення RAID 6 необхідно мінімум чотири фізичних диска: два для даних і два для парності.

6. **Висока вартість**: Через потребу у додаткових дисках для парності RAID 6 може бути вищою вартістю у порівнянні з іншими рівнями RAID.

RAID 6 використовується у випадках, коли висока надійність та можливість витримати відмову двох дисків є критичними. Він підходить для використання у великих серверах з великою кількістю даних, де важлива комбінація продуктивності та надійності.

### RAID 10

RAID 10, також відомий як RAID 1+0, - це комбінація рівнів RAID 1 і RAID 0. У RAID 10 дані розподіляються по декількох дисках у рівні RAID 0, а потім ці блоки даних дублюються на іншій групі дисків у рівні RAID 1. Така конфігурація забезпечує високий рівень продуктивності та надійності даних.

![RAID 10](images/raid10.png)

Основні характеристики RAID 10:

1. **Висока надійність**: RAID 10 може витримати відмову одного або навіть кількох дисків без втрати даних. При цьому можлива відмова одного диска у кожній підгрупі (RAID 1).

2. **Висока продуктивність читання і запису**: Через розподілення даних на кілька дисків у рівні RAID 0, RAID 10 забезпечує високу продуктивність читання та запису.

3. **Ефективність простору**: RAID 10 використовує половину доступного простору на дисках для зберігання даних, оскільки кожен блок даних дублюється.

4. **Вимога до мінімуму дисків**: Для створення RAID 10 потрібно як мінімум чотири диска.

5. **Висока вартість**: Через потребу у додаткових дисках для зберігання дубльованих даних RAID 10 може бути дорожчим у порівнянні з іншими рівнями RAID.

RAID 10 часто використовується у великих серверних середовищах, де вимоги до продуктивності та надійності є критичними. Він є оптимальним варіантом для тих, хто шукає високий рівень продуктивності та надійності, але готовий платити за це додатково.

### І решта

RAID 2 та RAID 3 — це два рівні RAID, які мало використовуються в сучасних системах через свою складність та обмежені переваги. Основні відмінності між ними полягають у способі організації та використанні паритету.

**RAID 2:**

- RAID 2 використовує бітовий рівень стріпінгу даних, що означає, що кожний біт даних розділяється на бітові частини, які зберігаються на різних дисках.
- RAID 2 використовує диск для зберігання бітів паритету, які використовуються для відновлення даних в разі відмови.
- Цей рівень RAID був розроблений як ефективний метод корекції помилок, але його складність та низька продуктивність призвели до того, що його мало хто використовує в практиці.

![RAID 2](images/raid2.png)

**RAID 3:**

- RAID 3 використовує блочний рівень стріпінгу даних, де кожен блок даних розділяється на блоки, які зберігаються на різних дисках.
- Однак, в RAID 3 є лише один диск, на якому зберігається паритет, що використовується для відновлення даних у випадку відмови.
- RAID 3 також має низьку продуктивність через велику кількість операцій вводу/виводу, які пов'язані з записом паритету на окремий диск.
- Цей рівень RAID також має обмеження щодо паралельного доступу до даних, оскільки всі операції вводу/виводу пов'язані з паритетом.

![RAID 3](images/raid3.png)

## Створення RAID Logical Volume

Щоб створити логічний том RAID, ви вказуєте тип рейду як аргумент `--type` команди `lvcreate`. Зазвичай, коли ви створюєте логічний том за допомогою команди `lvcreate`, аргумент `--type` є неявним. Наприклад, коли ви вказуєте аргумент `-i stripes`, команда `lvcreate` передбачає параметр `--type stripe`. Коли ви вказуєте аргумент `-m mirrors`, команда `lvcreate` передбачає параметр `--type mirror`. Однак, коли ви створюєте логічний том RAID, ви повинні явно вказати потрібний тип сегмента.

Можливі типи сегментів RAID:

- `raid1` — дзеркальне відображення RAID1
- `raid4` — виділений диск паритету RAID4
- `raid5` — обертовий паритет RAID5 із перезапуском даних
- `raid6` — нульовий паритет RAID6 із перезапуском даних
- `raid10` — смугасті дзеркала RAID10

Для більшості користувачів достатньо вказати один із п'яти доступних основних типів (`raid1`, `raid4`, `raid5`, `raid6`, `raid10`).

Коли ви створюєте логічний том RAID, LVM створює субтом метаданих, розмір якого становить один екстент для кожного субтому даних або паритету в масиві. Наприклад, створення двостороннього масиву RAID1 призводить до двох підтомів метаданих (`_lv_rmeta_0_` і `_lv_rmeta_1_`) і двох підтомів даних (`_lv_rimage_0_` і `_lv_rimage_1_`). Так само створення 3-сторонньої смуги (плюс 1 пристрій неявного паритету) RAID4 призводить до 4 підтомів метаданих (`_lv_rmeta_0_`, `_lv_rmeta_1_`, `_lv_rmeta_2_` і `_lv_rmeta_3_`) і 4 підтомів даних (`_lv_rimage_0_`, `_lv_rimage_1_`, `_lv_rimage_2_` і `_lv_rimage_3_`).

Наступна команда створює двосторонній масив RAID1 із назвою `my_lv` у групі томів `my_vg` розміром 1 ГБ:

```bash
lvcreate --type raid1 -m 1 -L 1G -n my_lv my_vg
```

Ви можете створювати масиви RAID1 з різною кількістю копій відповідно до значення, яке ви вказали для аргументу `-m`. Хоча аргумент `-m` є тим самим аргументом, який використовувався для визначення кількості копій для попередньої реалізації дзеркала, у цьому випадку ви замінюєте тип сегмента за замовчуванням `mirror`, явно встановлюючи тип сегмента як `raid1`. Так само ви вказуєте кількість смуг для логічного тому RAID 4/5/6 за допомогою знайомого аргументу `-i`, замінюючи тип сегмента за замовчуванням потрібним типом RAID. Ви також можете вказати розмір смуги за допомогою аргументу `-I`.

Наступна команда створює масив RAID5 (3 смуги + 1 диск неявного паритету) під назвою `my_lv` у групі томів `my_vg` розміром 1 ГБ:

```bash
lvcreate --type raid5 -i 3 -L 1G -n my_lv my_vg
```

Наступна команда створює масив RAID6 (3 смуги + 2 диски з неявним паритетом) під назвою `my_lv` у групі томів `my_vg` розміром 1 ГБ:

```bash
lvcreate --type raid6 -i 3 -L 1G -n my_lv my_vg
```

Створивши логічний том RAID за допомогою LVM, ви можете активувати, змінювати, видаляти, відображати та використовувати цей том так само, як будь-який інший логічний том LVM.

Коли ви створюєте логічні томи RAID10, фоновий ввід-вивід, необхідний для ініціалізації логічних томів за допомогою операції синхронізації, може витіснити інші операції вводу-виводу на пристроях LVM, наприклад оновлення метаданих групи томів, особливо коли ви створюєте багато Логічні томи RAID. Це може спричинити сповільнення інших операцій LVM.

Ви можете контролювати швидкість ініціалізації логічного тому RAID, реалізувавши регулювання відновлення. Ви контролюєте швидкість, з якою виконуються операції синхронізації, встановлюючи мінімальну та максимальну швидкість введення-виведення для цих операцій за допомогою параметрів `--minrecoveryrate` і `--maxrecoveryrate` команди `lvcreate`.

Ви вказуєте ці параметри наступним чином:

- `--maxrecoveryrate Rate[bBsSkKmMgG]` — встановлює максимальну швидкість відновлення для логічного тому RAID, щоб він не витісняв номінальні операції вводу/виводу. Швидкість вказується як кількість за секунду для кожного пристрою в масиві. Якщо суфікс не вказано, передбачається kiB/sec/device. Встановлення коефіцієнта відновлення на 0 означає, що він буде необмеженим.

- `--minrecoveryrate Rate[bBsSkKmMgG]` — встановлює мінімальну швидкість відновлення для логічного тому RAID, щоб гарантувати, що введення/виведення для операцій синхронізації досягає мінімальної пропускної здатності, навіть якщо присутній великий номінальний ввід/вивід. Швидкість вказується як кількість за секунду для кожного пристрою в масиві. Якщо суфікс не вказано, передбачається kiB/sec/device.

Наступна команда створює двосторонній масив RAID10 із 3 смугами розміром 10 ГБ із максимальною швидкістю відновлення 128 КБ/с/пристрій. Масив має назву `my_lv` і знаходиться в групі томів `my_vg`:

```bash
lvcreate --type raid10 -i 2 -m 1 -L 10G --maxrecoveryrate 128 -n my_lv my_vg
```

## Конвертація лінійного пристрою в RAID

Ви можете перетворити існуючий лінійний логічний том на пристрій RAID за допомогою аргументу `--type` команди `lvconvert`.

Наступна команда перетворює лінійний логічний том `my_lv` у групі томів `my_vg` на двосторонній масив RAID1:

```bash
lvconvert --type raid1 -m 1 my_vg/my_lv
```

Оскільки логічні томи RAID складаються з пар метаданих і вкладених томів даних, коли ви перетворюєте лінійний пристрій на масив RAID1, створюється новий вкладений том метаданих, який пов'язується з вихідним логічним томом на тому ж фізичному томі, що і лінійний том.

Додаткові образи додаються в парах метаданих/підтомів даних. Наприклад, якщо оригінальний пристрій виглядає так:

```bash
lvs -a -o name,copy_percent,devices my_vg
  LV     Copy%  Devices     
  my_lv         /dev/sde1(0)
```

Після перетворення на двосторонній масив RAID1 пристрій міститиме такі пари підтомів даних і метаданих:

```bash
lvconvert --type raid1 -m 1 my_vg/my_lv
lvs -a -o name,copy_percent,devices my_vg
  LV               Copy%  Devices                      
  my_lv            6.25   my_lv_rimage_0(0),my_lv_rimage_1(0)
  [my_lv_rimage_0]        /dev/sde1(0)                 
  [my_lv_rimage_1]        /dev/sdf1(1)                 
  [my_lv_rmeta_0]         /dev/sde1(256)               
  [my_lv_rmeta_1]         /dev/sdf1(0)
```

Якщо образ метаданих, який з'єднується з вихідним логічним томом, не можна розмістити на тому ж фізичному томі, `lvconvert` не вдасться виконати.
